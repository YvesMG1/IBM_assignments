{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install packages, GPU and Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.colors as colors\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "from collections import Counter\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Custom\n",
    "from cust_functions.processing_helper import *\n",
    "from cust_functions.models import *\n",
    "from cust_functions.training_helper import *\n",
    "from cust_functions.datavis_helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch CUDA available: True\n",
      "Number of GPUs: 2\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "print(\"Torch CUDA available:\", torch.cuda.is_available())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n",
    "print(\"Current GPU:\", torch.cuda.current_device())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define seed\n",
    "\"\"\"\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validation set (optional, data already precomputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home\"\n",
    "base_path = f\"{directory}/pf/pfstud/mlarriere/aligned_data/\"\n",
    "dw_path = f\"{directory}/pf/pfstud/mlarriere/DW_files/DW_timeslices/\"\n",
    "\n",
    "tile_lengths = {'tile0': 36, 'tile1': 26, 'tile3': 16, 'tile4': 22}\n",
    "tiles = [0, 1, 3, 4]\n",
    "\n",
    "# create files for all h5 image tiles\n",
    "tile0 = [f\"{base_path}tile0_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile0'])]\n",
    "tile1 = [f\"{base_path}tile1_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile1'])]\n",
    "tile3 = [f\"{base_path}tile3_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile3'])]\n",
    "tile4 = [f\"{base_path}tile4_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile4'])]\n",
    "h5_files = tile0 + tile1 + tile3 + tile4\n",
    "\n",
    "# create files for all h5 land cover tiles\n",
    "dw_tile0 = [f\"{dw_path}scaled_cloudy_tile_0_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile0'])]\n",
    "dw_tile1 = [f\"{dw_path}scaled_cloudy_tile_1_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile1'])]\n",
    "dw_tile3 = [f\"{dw_path}scaled_cloudy_tile_3_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile3'])]\n",
    "dw_tile4 = [f\"{dw_path}scaled_cloudy_tile_4_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile4'])]\n",
    "dw_files_scaled_cloudy = dw_tile0 + dw_tile1 + dw_tile3 + dw_tile4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 x 256 patches with 3 time slices\n",
    "file_names = {'CLD': 'CLD', 'RGB': 'RGB', 'NIR': 'NIR'}\n",
    "dw_file_name = 'DW_cloudy'\n",
    "dataset_full = H5Dataset_early(h5_files, dw_files_scaled_cloudy, file_name = file_names, dw_file_name=dw_file_name, patch_size=(256, 256), cloud_threshold = 1.0, \n",
    "                         calculate_time_slice_indices=False, time_file_name='time_slice_indices_precomputed_256_early3.pkl', timesteps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 256 x 256 patches with 5 time slices\n",
    "file_names = {'CLD': 'CLD', 'RGB': 'RGB', 'NIR': 'NIR'}\n",
    "dw_file_name = 'DW_cloudy'\n",
    "dataset_full5 = H5Dataset_early(h5_files, dw_files_scaled_cloudy, file_name = file_names, dw_file_name=dw_file_name, patch_size=(256, 256), cloud_threshold = 1.0, \n",
    "                         calculate_time_slice_indices=False, time_file_name='time_slice_indices_precomputed_256_early5.pkl', timesteps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11630\n"
     ]
    }
   ],
   "source": [
    "# load indices from file for 256 x 256 patches with 3 time slices\n",
    "with open('val_indices_256.pkl', 'rb') as f:\n",
    "    val_indices_256 = pickle.load(f)\n",
    "\n",
    "val_dataset_256_early3 = torch.utils.data.Subset(dataset_full, val_indices_256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11630\n"
     ]
    }
   ],
   "source": [
    "# load indices from file for 256 x 256 patches with 5 time slices\n",
    "with open('val_indices_256.pkl', 'rb') as f:\n",
    "    val_indices_256 = pickle.load(f)\n",
    "    print(len(val_indices_256))\n",
    "\n",
    "val_dataset_256_early5 = torch.utils.data.Subset(dataset_full5, val_indices_256)\n",
    "save_dir = '/home/pf/pfstud/mlarriere/preprocessed_val_data_256_early5'\n",
    "save_preprocessed_data(val_dataset_256_early5, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load val datasets ###\n",
    "with open('precomputed_indices/val_indices_256.pkl', 'rb') as f:\n",
    "    val_indices_256 = pickle.load(f)\n",
    "    \n",
    "preprocessed_val_dataset_256_early3 = PreprocessedValDataset('/home/pf/pfstud/mlarriere/preprocessed_val_data_256_early3')\n",
    "preprocessed_val_dataset_256_early5 = PreprocessedValDataset('/home/pf/pfstud/mlarriere/preprocessed_val_data_256_early5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. 3 Time Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"/home\"\n",
    "# directory = \"P:\"\n",
    "base_path = f\"{directory}/pf/pfstud/mlarriere/aligned_data/\"\n",
    "dw_path = f\"{directory}/pf/pfstud/mlarriere/DW_files/DW_timeslices/\"\n",
    "\n",
    "# File names with time steps\n",
    "tile_lengths = {'tile0': 36, 'tile1': 26, 'tile3': 16, 'tile4': 22}\n",
    "tiles = [0, 1, 3, 4]\n",
    "\n",
    "\n",
    "# create files for all h5 image tiles\n",
    "tile0 = [f\"{base_path}tile0_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile0'])]\n",
    "tile1 = [f\"{base_path}tile1_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile1'])]\n",
    "tile3 = [f\"{base_path}tile3_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile3'])]\n",
    "tile4 = [f\"{base_path}tile4_aligned_{timestep}.h5\" for timestep in range(0, tile_lengths['tile4'])]\n",
    "h5_files = tile0 + tile1 + tile3 + tile4\n",
    "\n",
    "# create files for all h5 land cover tiles\n",
    "dw_tile0 = [f\"{dw_path}scaled_cloudy_tile_0_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile0'])]\n",
    "dw_tile1 = [f\"{dw_path}scaled_cloudy_tile_1_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile1'])]\n",
    "dw_tile3 = [f\"{dw_path}scaled_cloudy_tile_3_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile3'])]\n",
    "dw_tile4 = [f\"{dw_path}scaled_cloudy_tile_4_dw_{timestep}.h5\" for timestep in range(0, tile_lengths['tile4'])]\n",
    "dw_files_scaled_cloudy = dw_tile0 + dw_tile1 + dw_tile3 + dw_tile4\n",
    "\n",
    "file_names = {'CLD': 'CLD', 'RGB': 'RGB', 'NIR': 'NIR'}\n",
    "dw_file_name = 'DW_cloudy'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_threshold = 1.0\n",
    "dataset_fusion_early3 = H5Dataset_early(h5_files, dw_files_scaled_cloudy, file_name = file_names, dw_file_name=dw_file_name, patch_size=(256, 256), cloud_threshold = 1.0, \n",
    "                         calculate_time_slice_indices=False, time_file_name='time_slice_indices_precomputed_256_early3.pkl')\n",
    "dataset_fusion_early3 = torch.utils.data.Subset(dataset_fusion_early3, list(set(range(len(dataset_fusion_early3))) - set(val_dataset_256_early3.indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "NUM_CHANNELS = 12 # input dimension: 4 channels (R, G, B, NIR)\n",
    "NUM_CLASSES = 11\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 8, 7, 9, 10]  # 0-10\n",
    "exlude_classes = [0, 8, 10] #8: snow & ice, 10: clouds\n",
    "reduced_classes = [1, 2, 3, 4, 5, 6, 7, 9] #1: trees, 2: grass, 3: flooded veg., 4: crops, 5: shrub & scrub, 6: built-up, 7: bare, 9: water\n",
    "\n",
    "num_epochs = 40\n",
    "lr = 0.001 # 0.001\n",
    "weight_decay = 1e-5\n",
    "batch_size_train = 32\n",
    "batch_size_val = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset_fusion_early3, batch_size=batch_size_train, shuffle=False, num_workers=8)\n",
    "val_dataloader = DataLoader(preprocessed_val_dataset_256_early3, batch_size=batch_size_val, shuffle=False, num_workers=8)\n",
    "model = Unet_DW(NUM_CHANNELS, NUM_CLASSES)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "weights = torch.tensor([0.05, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05, 1.0, 1.0]).to(device) \n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=5)\n",
    "\n",
    "# Initiate epoch metrics\n",
    "train_results = {\n",
    "    \"train_loss\": [],\n",
    "}\n",
    "\n",
    "val_results = {\n",
    "    \"val_loss\": [],\n",
    "    \"best_val_accuracy\": 0.0,\n",
    "    \"best_val_f1_score\": 0.0,\n",
    "    \"best_val_recall\": 0.0,\n",
    "    \"best_val_precision\": 0.0,\n",
    "}\n",
    "\n",
    "# store best model of reduced classes\n",
    "best_f1_scores_per_class = {f'class{i}': -1 for i in reduced_classes}\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "patience = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "for epoch in range(num_epochs):   \n",
    "\n",
    "    # train and validate model\n",
    "    running_loss = train_model(model, optimizer, criterion, train_dataloader, device, NUM_CLASSES)\n",
    "    running_val_loss = validate_model_simple(model, criterion, val_dataloader, device)\n",
    "\n",
    "     # Early stopping\n",
    "    if running_val_loss < best_val_loss:\n",
    "        best_val_loss = running_val_loss\n",
    "        best_model = model.state_dict().copy()\n",
    "        best_epoch = epoch\n",
    "        patience = 10\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "    \n",
    "    # Update results lists\n",
    "    train_results[\"train_loss\"].append(epoch_train_loss)\n",
    "    val_results[\"val_loss\"].append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train loss {epoch_train_loss:.4f}, validation loss {epoch_val_loss:.4f}\") \n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "# Do one full validation with the best model\n",
    "model.load_state_dict(best_model)\n",
    "_, running_val_confusion_matrix = validate_model(model, criterion, val_dataloader, device, NUM_CLASSES, class_labels)\n",
    "running_val_confusion_matrix_reduced = calculate_reduced_confusion_matrix(running_val_confusion_matrix, exlude_classes)\n",
    "\n",
    "# Update best f1 scores per class\n",
    "val_precision, val_recall, val_f1_score = calculate_metrics(running_val_confusion_matrix_reduced)\n",
    "\n",
    "for i, f1 in enumerate(val_f1_score):\n",
    "    best_f1_scores_per_class[f'class{i}'] = f1\n",
    "\n",
    "# Calculate average metrics\n",
    "val_precision_avg = val_precision.mean()\n",
    "val_recall_avg = val_recall.mean()\n",
    "val_f1_score_avg = val_f1_score.mean()\n",
    "val_accuracy = running_val_confusion_matrix_reduced.trace() / running_val_confusion_matrix.sum()\n",
    "\n",
    "# Update results lists\n",
    "# replace last value with best value of best epoch\n",
    "val_results[\"best_val_accuracy\"] = val_accuracy\n",
    "val_results[\"best_val_precision\"] = val_precision_avg\n",
    "val_results[\"best_val_recall\"] = val_recall_avg\n",
    "val_results[\"best_val_f1_score\"] = val_f1_score_avg\n",
    "\n",
    "# Save model\n",
    "saved_f1 = np.round(val_results[\"best_val_f1_score\"], 2)\n",
    "PATH = f\"EarlyFusioCNN3_bestf1_{saved_f1}.pth\"\n",
    "torch.save(best_model, PATH)\n",
    "\n",
    "# Plot results\n",
    "plot_loss(train_results, val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 5 Time Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_threshold = 1.0\n",
    "file_names = {'CLD': 'CLD', 'RGB': 'RGB', 'NIR': 'NIR'}\n",
    "dw_file_name = 'DW_cloudy'\n",
    "dataset_fusion_early5 = H5Dataset_early(h5_files, dw_files_scaled_cloudy, file_name = file_names, dw_file_name=dw_file_name, patch_size=(256, 256), cloud_threshold = 1.0, \n",
    "                         calculate_time_slice_indices=False, time_file_name='time_slice_indices_precomputed_256_early5.pkl', timesteps=5)\n",
    "dataset_fusion_early5 = torch.utils.data.Subset(dataset_fusion_early5, list(set(range(len(dataset_fusion_early5))) - set(val_dataset_256_early5.indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "NUM_CHANNELS = 20 # input dimension: 4 channels (R, G, B, NIR)\n",
    "NUM_CLASSES = 11\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]  # 0-10\n",
    "exlude_classes = [0, 8, 10] #8: snow & ice, 10: clouds\n",
    "reduced_classes = [1, 2, 3, 4, 5, 6, 7, 9] #1: trees, 2: grass, 3: flooded veg., 4: crops, 5: shrub & scrub, 6: built-up, 7: bare, 9: water\n",
    "\n",
    "num_epochs = 40\n",
    "lr = 0.001 # 0.001\n",
    "weight_decay = 1e-5\n",
    "batch_size_train = 32\n",
    "batch_size_val = 16\n",
    "\n",
    "train_dataloader = DataLoader(dataset_fusion_early5, batch_size=batch_size_train, shuffle=False, num_workers=8)\n",
    "val_dataloader = DataLoader(val_dataset_256_early5, batch_size=batch_size_val, shuffle=False, num_workers=8)\n",
    "model = Unet_DW(NUM_CHANNELS, NUM_CLASSES)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "weights = torch.tensor([0.05, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05, 1.0, 1.0]).to(device) \n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=5)\n",
    "\n",
    "# Initiate epoch metrics\n",
    "train_results = {\n",
    "    \"train_loss\": [],\n",
    "}\n",
    "\n",
    "val_results = {\n",
    "    \"val_loss\": [],\n",
    "    \"best_val_accuracy\": 0.0,\n",
    "    \"best_val_f1_score\": 0.0,\n",
    "    \"best_val_recall\": 0.0,\n",
    "    \"best_val_precision\": 0.0,\n",
    "}\n",
    "\n",
    "# store best model of reduced classes\n",
    "best_f1_scores_per_class = {f'class{i}': -1 for i in reduced_classes}\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "patience = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "for epoch in range(num_epochs):   \n",
    "\n",
    "    # train and validate model\n",
    "    running_loss = train_model(model, optimizer, criterion, train_dataloader, device, NUM_CLASSES)\n",
    "    running_val_loss = validate_model_simple(model, criterion, val_dataloader, device)\n",
    "\n",
    "     # Early stopping\n",
    "    if running_val_loss < best_val_loss:\n",
    "        best_val_loss = running_val_loss\n",
    "        best_model = model.state_dict().copy()\n",
    "        best_epoch = epoch\n",
    "        patience = 10\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "    \n",
    "    # Update results lists\n",
    "    train_results[\"train_loss\"].append(epoch_train_loss)\n",
    "    val_results[\"val_loss\"].append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train loss {epoch_train_loss:.4f}, validation loss {epoch_val_loss:.4f}\") \n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "# Do one full validation with the best model\n",
    "model.load_state_dict(best_model)\n",
    "_, running_val_confusion_matrix = validate_model(model, criterion, val_dataloader, device, NUM_CLASSES, class_labels)\n",
    "running_val_confusion_matrix_reduced = calculate_reduced_confusion_matrix(running_val_confusion_matrix, exlude_classes)\n",
    "\n",
    "# Update best f1 scores per class\n",
    "val_precision, val_recall, val_f1_score = calculate_metrics(running_val_confusion_matrix_reduced)\n",
    "\n",
    "for i, f1 in enumerate(val_f1_score):\n",
    "    best_f1_scores_per_class[f'class{i}'] = f1\n",
    "\n",
    "# Calculate average metrics\n",
    "val_precision_avg = val_precision.mean()\n",
    "val_recall_avg = val_recall.mean()\n",
    "val_f1_score_avg = val_f1_score.mean()\n",
    "val_accuracy = running_val_confusion_matrix_reduced.trace() / running_val_confusion_matrix.sum()\n",
    "\n",
    "# Update results lists\n",
    "# replace last value with best value of best epoch\n",
    "val_results[\"best_val_accuracy\"] = val_accuracy\n",
    "val_results[\"best_val_precision\"] = val_precision_avg\n",
    "val_results[\"best_val_recall\"] = val_recall_avg\n",
    "val_results[\"best_val_f1_score\"] = val_f1_score_avg\n",
    "\n",
    "# Save model\n",
    "saved_f1 = np.round(val_results[\"best_val_f1_score\"], 2)\n",
    "PATH = f\"EarlyFusionCNN5_bestf1_{saved_f1}.pth\"\n",
    "torch.save(best_model, PATH)\n",
    "\n",
    "# Plot results\n",
    "plot_loss(train_results, val_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 With Attention, 3 Time Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cld_threshold = 1.0\n",
    "file_names = {'CLD': 'CLD', 'RGB': 'RGB', 'NIR': 'NIR'}\n",
    "dw_file_name = 'DW_cloudy'\n",
    "dataset_fusion_early3 = H5Dataset_early(h5_files, dw_files_scaled_cloudy, file_name = file_names, dw_file_name=dw_file_name, patch_size=(256, 256), cloud_threshold = 1.0, \n",
    "                         calculate_time_slice_indices=False, time_file_name='time_slice_indices_precomputed_256_early3.pkl')\n",
    "# exlude validation dataset from baseline dataset\n",
    "dataset_fusion_early3 = torch.utils.data.Subset(dataset_fusion_early3, list(set(range(len(dataset_fusion_early3))) - set(val_dataset_256_early3.indices)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "NUM_CHANNELS = 12 # input dimension: 4 channels (R, G, B, NIR)\n",
    "NUM_CLASSES = 11\n",
    "class_labels = [0, 1, 2, 3, 4, 5, 6, 8, 7, 9, 10]  # 0-10\n",
    "exlude_classes = [0, 8, 10] #8: snow & ice, 10: clouds\n",
    "reduced_classes = [1, 2, 3, 4, 5, 6, 7, 9] #1: trees, 2: grass, 3: flooded veg., 4: crops, 5: shrub & scrub, 6: built-up, 7: bare, 9: water\n",
    "\n",
    "num_epochs = 40\n",
    "lr = 0.001 # 0.001\n",
    "weight_decay = 1e-5\n",
    "batch_size_train = 32\n",
    "batch_size_val = 32\n",
    "\n",
    "train_dataloader = DataLoader(dataset_fusion_early3, batch_size=batch_size_train, shuffle=False, num_workers=8)\n",
    "val_dataloader = DataLoader(preprocessed_val_dataset_256_early3, batch_size=batch_size_val, shuffle=False, num_workers=8)\n",
    "model = Unet_DW_attention(NUM_CHANNELS, NUM_CLASSES)\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "weights = torch.tensor([0.05, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.05, 1.0, 1.0]).to(device) \n",
    "criterion = nn.CrossEntropyLoss(weight=weights)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.25, patience=5)\n",
    "\n",
    "# Initiate epoch metrics\n",
    "train_results = {\n",
    "    \"train_loss\": [],\n",
    "}\n",
    "\n",
    "val_results = {\n",
    "    \"val_loss\": [],\n",
    "    \"best_val_accuracy\": 0.0,\n",
    "    \"best_val_f1_score\": 0.0,\n",
    "    \"best_val_recall\": 0.0,\n",
    "    \"best_val_precision\": 0.0,\n",
    "}\n",
    "\n",
    "# store best model of reduced classes\n",
    "best_f1_scores_per_class = {f'class{i}': -1 for i in reduced_classes}\n",
    "\n",
    "best_val_loss = np.inf\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "patience = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "for epoch in range(num_epochs):   \n",
    "\n",
    "    # train and validate model\n",
    "    running_loss = train_model(model, optimizer, criterion, train_dataloader, device, NUM_CLASSES)\n",
    "    running_val_loss = validate_model_simple(model, criterion, val_dataloader, device)\n",
    "\n",
    "     # Early stopping\n",
    "    if running_val_loss < best_val_loss:\n",
    "        best_val_loss = running_val_loss\n",
    "        best_model = model.state_dict().copy()\n",
    "        best_epoch = epoch\n",
    "        patience = 10\n",
    "    else:\n",
    "        patience -= 1\n",
    "        if patience == 0:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "    # Calculate epoch metrics\n",
    "    epoch_train_loss = running_loss / len(train_dataloader)\n",
    "    epoch_val_loss = running_val_loss / len(val_dataloader)\n",
    "    \n",
    "    # Update results lists\n",
    "    train_results[\"train_loss\"].append(epoch_train_loss)\n",
    "    val_results[\"val_loss\"].append(epoch_val_loss)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: train loss {epoch_train_loss:.4f}, validation loss {epoch_val_loss:.4f}\") \n",
    "\n",
    "    # Update learning rate\n",
    "    scheduler.step(epoch_val_loss)\n",
    "\n",
    "# Do one full validation with the best model\n",
    "model.load_state_dict(best_model)\n",
    "_, running_val_confusion_matrix = validate_model(model, criterion, val_dataloader, device, NUM_CLASSES, class_labels)\n",
    "running_val_confusion_matrix_reduced = calculate_reduced_confusion_matrix(running_val_confusion_matrix, exlude_classes)\n",
    "\n",
    "# Update best f1 scores per class\n",
    "val_precision, val_recall, val_f1_score = calculate_metrics(running_val_confusion_matrix_reduced)\n",
    "\n",
    "for i, f1 in enumerate(val_f1_score):\n",
    "    best_f1_scores_per_class[f'class{i}'] = f1\n",
    "\n",
    "# Calculate average metrics\n",
    "val_precision_avg = val_precision.mean()\n",
    "val_recall_avg = val_recall.mean()\n",
    "val_f1_score_avg = val_f1_score.mean()\n",
    "val_accuracy = running_val_confusion_matrix_reduced.trace() / running_val_confusion_matrix.sum()\n",
    "\n",
    "# Update results lists\n",
    "# replace last value with best value of best epoch\n",
    "val_results[\"best_val_accuracy\"] = val_accuracy\n",
    "val_results[\"best_val_precision\"] = val_precision_avg\n",
    "val_results[\"best_val_recall\"] = val_recall_avg\n",
    "val_results[\"best_val_f1_score\"] = val_f1_score_avg\n",
    "\n",
    "# Save model\n",
    "saved_f1 = np.round(val_results[\"best_val_f1_score\"], 2)\n",
    "PATH = f\"EarlyFusioCNN3_bestf1_{saved_f1}.pth\"\n",
    "torch.save(best_model, PATH)\n",
    "\n",
    "# Plot results\n",
    "plot_loss(train_results, val_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ImgMap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
